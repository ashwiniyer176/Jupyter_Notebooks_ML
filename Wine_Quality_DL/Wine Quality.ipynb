{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Layer Perceptron Model\n",
    "\n",
    "Using the Single Layer Perceptron, we try to predict the Wine Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('winequality-red.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "4     53\n",
       "8     18\n",
       "3     10\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=[df.shape[1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential([\n",
    "    layers.Dense(units=1,input_shape=shape)    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=[\"quality\"])\n",
    "y=df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "1       5\n",
       "2       5\n",
       "3       6\n",
       "4       5\n",
       "       ..\n",
       "1594    5\n",
       "1595    6\n",
       "1596    6\n",
       "1597    5\n",
       "1598    6\n",
       "Name: quality, Length: 1599, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mae', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 15.1122 - val_loss: 6.7449\n",
      "Epoch 2/100\n",
      "128/128 [==============================] - 0s 793us/step - loss: 5.3300 - val_loss: 3.6992\n",
      "Epoch 3/100\n",
      "128/128 [==============================] - 0s 806us/step - loss: 3.5566 - val_loss: 3.4263\n",
      "Epoch 4/100\n",
      "128/128 [==============================] - 0s 845us/step - loss: 3.1559 - val_loss: 3.1206\n",
      "Epoch 5/100\n",
      "128/128 [==============================] - 0s 774us/step - loss: 2.9051 - val_loss: 2.7989\n",
      "Epoch 6/100\n",
      "128/128 [==============================] - 0s 814us/step - loss: 2.4638 - val_loss: 2.4642\n",
      "Epoch 7/100\n",
      "128/128 [==============================] - 0s 727us/step - loss: 2.2573 - val_loss: 2.1218\n",
      "Epoch 8/100\n",
      "128/128 [==============================] - 0s 744us/step - loss: 1.9432 - val_loss: 1.7992\n",
      "Epoch 9/100\n",
      "128/128 [==============================] - 0s 786us/step - loss: 1.7148 - val_loss: 1.4503\n",
      "Epoch 10/100\n",
      "128/128 [==============================] - 0s 832us/step - loss: 1.2964 - val_loss: 1.1434\n",
      "Epoch 11/100\n",
      "128/128 [==============================] - 0s 784us/step - loss: 1.0334 - val_loss: 0.9174\n",
      "Epoch 12/100\n",
      "128/128 [==============================] - 0s 762us/step - loss: 0.8383 - val_loss: 0.7072\n",
      "Epoch 13/100\n",
      "128/128 [==============================] - 0s 750us/step - loss: 0.6986 - val_loss: 0.6386\n",
      "Epoch 14/100\n",
      "128/128 [==============================] - 0s 757us/step - loss: 0.6391 - val_loss: 0.6152\n",
      "Epoch 15/100\n",
      "128/128 [==============================] - 0s 777us/step - loss: 0.6348 - val_loss: 0.5999\n",
      "Epoch 16/100\n",
      "128/128 [==============================] - 0s 748us/step - loss: 0.6173 - val_loss: 0.5891\n",
      "Epoch 17/100\n",
      "128/128 [==============================] - 0s 733us/step - loss: 0.5982 - val_loss: 0.5918\n",
      "Epoch 18/100\n",
      "128/128 [==============================] - 0s 820us/step - loss: 0.5824 - val_loss: 0.5703\n",
      "Epoch 19/100\n",
      "128/128 [==============================] - 0s 771us/step - loss: 0.5978 - val_loss: 0.5620\n",
      "Epoch 20/100\n",
      "128/128 [==============================] - 0s 741us/step - loss: 0.5615 - val_loss: 0.5520\n",
      "Epoch 21/100\n",
      "128/128 [==============================] - 0s 754us/step - loss: 0.5401 - val_loss: 0.5445\n",
      "Epoch 22/100\n",
      "128/128 [==============================] - 0s 774us/step - loss: 0.5512 - val_loss: 0.5402\n",
      "Epoch 23/100\n",
      "128/128 [==============================] - 0s 738us/step - loss: 0.5372 - val_loss: 0.5392\n",
      "Epoch 24/100\n",
      "128/128 [==============================] - 0s 759us/step - loss: 0.5308 - val_loss: 0.5461\n",
      "Epoch 25/100\n",
      "128/128 [==============================] - 0s 767us/step - loss: 0.5237 - val_loss: 0.5579\n",
      "Epoch 26/100\n",
      "128/128 [==============================] - 0s 747us/step - loss: 0.5212 - val_loss: 0.5354\n",
      "Epoch 27/100\n",
      "128/128 [==============================] - 0s 764us/step - loss: 0.5316 - val_loss: 0.5387\n",
      "Epoch 28/100\n",
      "128/128 [==============================] - 0s 777us/step - loss: 0.4973 - val_loss: 0.5347\n",
      "Epoch 29/100\n",
      "128/128 [==============================] - 0s 762us/step - loss: 0.5224 - val_loss: 0.5356\n",
      "Epoch 30/100\n",
      "128/128 [==============================] - 0s 724us/step - loss: 0.5156 - val_loss: 0.5360\n",
      "Epoch 31/100\n",
      "128/128 [==============================] - 0s 747us/step - loss: 0.5179 - val_loss: 0.5366\n",
      "Epoch 32/100\n",
      "128/128 [==============================] - 0s 811us/step - loss: 0.5128 - val_loss: 0.5347\n",
      "Epoch 33/100\n",
      "128/128 [==============================] - 0s 777us/step - loss: 0.5276 - val_loss: 0.5336\n",
      "Epoch 34/100\n",
      "128/128 [==============================] - 0s 742us/step - loss: 0.5248 - val_loss: 0.5340\n",
      "Epoch 35/100\n",
      "128/128 [==============================] - 0s 738us/step - loss: 0.5240 - val_loss: 0.5307\n",
      "Epoch 36/100\n",
      "128/128 [==============================] - 0s 781us/step - loss: 0.5008 - val_loss: 0.5307\n",
      "Epoch 37/100\n",
      "128/128 [==============================] - 0s 770us/step - loss: 0.5496 - val_loss: 0.5315\n",
      "Epoch 38/100\n",
      "128/128 [==============================] - 0s 761us/step - loss: 0.5148 - val_loss: 0.5412\n",
      "Epoch 39/100\n",
      "128/128 [==============================] - 0s 793us/step - loss: 0.5525 - val_loss: 0.5324\n",
      "Epoch 40/100\n",
      "128/128 [==============================] - 0s 737us/step - loss: 0.5185 - val_loss: 0.5288\n",
      "Epoch 41/100\n",
      "128/128 [==============================] - 0s 762us/step - loss: 0.5082 - val_loss: 0.5533\n",
      "Epoch 42/100\n",
      "128/128 [==============================] - 0s 762us/step - loss: 0.5257 - val_loss: 0.5313\n",
      "Epoch 43/100\n",
      "128/128 [==============================] - 0s 856us/step - loss: 0.5117 - val_loss: 0.5299\n",
      "Epoch 44/100\n",
      "128/128 [==============================] - 0s 793us/step - loss: 0.5471 - val_loss: 0.5308\n",
      "Epoch 45/100\n",
      "128/128 [==============================] - 0s 805us/step - loss: 0.5351 - val_loss: 0.5262\n",
      "Epoch 46/100\n",
      "128/128 [==============================] - 0s 946us/step - loss: 0.4980 - val_loss: 0.5936\n",
      "Epoch 47/100\n",
      "128/128 [==============================] - 0s 872us/step - loss: 0.5266 - val_loss: 0.5282\n",
      "Epoch 48/100\n",
      "128/128 [==============================] - 0s 860us/step - loss: 0.5084 - val_loss: 0.5335\n",
      "Epoch 49/100\n",
      "128/128 [==============================] - 0s 880us/step - loss: 0.5068 - val_loss: 0.5229\n",
      "Epoch 50/100\n",
      "128/128 [==============================] - 0s 817us/step - loss: 0.4874 - val_loss: 0.5251\n",
      "Epoch 51/100\n",
      "128/128 [==============================] - 0s 798us/step - loss: 0.5093 - val_loss: 0.5281\n",
      "Epoch 52/100\n",
      "128/128 [==============================] - 0s 719us/step - loss: 0.5205 - val_loss: 0.5261\n",
      "Epoch 53/100\n",
      "128/128 [==============================] - 0s 738us/step - loss: 0.5143 - val_loss: 0.5240\n",
      "Epoch 54/100\n",
      "128/128 [==============================] - 0s 729us/step - loss: 0.5006 - val_loss: 0.5446\n",
      "Epoch 55/100\n",
      "128/128 [==============================] - 0s 743us/step - loss: 0.5018 - val_loss: 0.5292\n",
      "Epoch 56/100\n",
      "128/128 [==============================] - 0s 767us/step - loss: 0.4827 - val_loss: 0.5424\n",
      "Epoch 57/100\n",
      "128/128 [==============================] - 0s 780us/step - loss: 0.5418 - val_loss: 0.5227\n",
      "Epoch 58/100\n",
      "128/128 [==============================] - 0s 825us/step - loss: 0.5229 - val_loss: 0.5231\n",
      "Epoch 59/100\n",
      "128/128 [==============================] - 0s 730us/step - loss: 0.5216 - val_loss: 0.5221\n",
      "Epoch 60/100\n",
      "128/128 [==============================] - 0s 793us/step - loss: 0.5090 - val_loss: 0.5340\n",
      "Epoch 61/100\n",
      "128/128 [==============================] - 0s 756us/step - loss: 0.5046 - val_loss: 0.5241\n",
      "Epoch 62/100\n",
      "128/128 [==============================] - 0s 674us/step - loss: 0.5598 - val_loss: 0.5455\n",
      "Epoch 63/100\n",
      "128/128 [==============================] - 0s 746us/step - loss: 0.5349 - val_loss: 0.5197\n",
      "Epoch 64/100\n",
      "128/128 [==============================] - 0s 777us/step - loss: 0.5208 - val_loss: 0.5209\n",
      "Epoch 65/100\n",
      "128/128 [==============================] - 0s 728us/step - loss: 0.5220 - val_loss: 0.5275\n",
      "Epoch 66/100\n",
      "128/128 [==============================] - 0s 754us/step - loss: 0.4984 - val_loss: 0.5202\n",
      "Epoch 67/100\n",
      "128/128 [==============================] - 0s 717us/step - loss: 0.4907 - val_loss: 0.5191\n",
      "Epoch 68/100\n",
      "128/128 [==============================] - 0s 796us/step - loss: 0.4912 - val_loss: 0.5212\n",
      "Epoch 69/100\n",
      "128/128 [==============================] - 0s 738us/step - loss: 0.5076 - val_loss: 0.5542\n",
      "Epoch 70/100\n",
      "128/128 [==============================] - 0s 747us/step - loss: 0.5220 - val_loss: 0.5339\n",
      "Epoch 71/100\n",
      "128/128 [==============================] - 0s 762us/step - loss: 0.5085 - val_loss: 0.5214\n",
      "Epoch 72/100\n",
      "128/128 [==============================] - 0s 775us/step - loss: 0.5125 - val_loss: 0.5174\n",
      "Epoch 73/100\n",
      "128/128 [==============================] - 0s 728us/step - loss: 0.4946 - val_loss: 0.5233\n",
      "Epoch 74/100\n",
      "128/128 [==============================] - 0s 753us/step - loss: 0.5155 - val_loss: 0.5190\n",
      "Epoch 75/100\n",
      "128/128 [==============================] - 0s 707us/step - loss: 0.4957 - val_loss: 0.5408\n",
      "Epoch 76/100\n",
      "128/128 [==============================] - 0s 802us/step - loss: 0.5066 - val_loss: 0.5160\n",
      "Epoch 77/100\n",
      "128/128 [==============================] - 0s 775us/step - loss: 0.4969 - val_loss: 0.5189\n",
      "Epoch 78/100\n",
      "128/128 [==============================] - 0s 792us/step - loss: 0.4970 - val_loss: 0.5175\n",
      "Epoch 79/100\n",
      "128/128 [==============================] - 0s 766us/step - loss: 0.5208 - val_loss: 0.5151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "128/128 [==============================] - 0s 722us/step - loss: 0.4829 - val_loss: 0.5362\n",
      "Epoch 81/100\n",
      "128/128 [==============================] - 0s 706us/step - loss: 0.5157 - val_loss: 0.5233\n",
      "Epoch 82/100\n",
      "128/128 [==============================] - 0s 735us/step - loss: 0.5008 - val_loss: 0.5205\n",
      "Epoch 83/100\n",
      "128/128 [==============================] - 0s 769us/step - loss: 0.5264 - val_loss: 0.5578\n",
      "Epoch 84/100\n",
      "128/128 [==============================] - 0s 771us/step - loss: 0.5075 - val_loss: 0.5179\n",
      "Epoch 85/100\n",
      "128/128 [==============================] - 0s 738us/step - loss: 0.4993 - val_loss: 0.5160\n",
      "Epoch 86/100\n",
      "128/128 [==============================] - 0s 730us/step - loss: 0.5009 - val_loss: 0.5151\n",
      "Epoch 87/100\n",
      "128/128 [==============================] - 0s 777us/step - loss: 0.5037 - val_loss: 0.5244\n",
      "Epoch 88/100\n",
      "128/128 [==============================] - 0s 743us/step - loss: 0.5116 - val_loss: 0.5335\n",
      "Epoch 89/100\n",
      "128/128 [==============================] - 0s 734us/step - loss: 0.4976 - val_loss: 0.5200\n",
      "Epoch 90/100\n",
      "128/128 [==============================] - 0s 769us/step - loss: 0.5295 - val_loss: 0.5275\n",
      "Epoch 91/100\n",
      "128/128 [==============================] - 0s 751us/step - loss: 0.5161 - val_loss: 0.5145\n",
      "Epoch 92/100\n",
      "128/128 [==============================] - 0s 697us/step - loss: 0.5268 - val_loss: 0.5304\n",
      "Epoch 93/100\n",
      "128/128 [==============================] - 0s 779us/step - loss: 0.5135 - val_loss: 0.5203\n",
      "Epoch 94/100\n",
      "128/128 [==============================] - 0s 783us/step - loss: 0.5082 - val_loss: 0.5413\n",
      "Epoch 95/100\n",
      "128/128 [==============================] - 0s 722us/step - loss: 0.5196 - val_loss: 0.5209\n",
      "Epoch 96/100\n",
      "128/128 [==============================] - 0s 745us/step - loss: 0.5104 - val_loss: 0.5152\n",
      "Epoch 97/100\n",
      "128/128 [==============================] - 0s 756us/step - loss: 0.5163 - val_loss: 0.5198\n",
      "Epoch 98/100\n",
      "128/128 [==============================] - 0s 726us/step - loss: 0.4861 - val_loss: 0.5131\n",
      "Epoch 99/100\n",
      "128/128 [==============================] - 0s 822us/step - loss: 0.5158 - val_loss: 0.5155\n",
      "Epoch 100/100\n",
      "128/128 [==============================] - 0s 750us/step - loss: 0.4783 - val_loss: 0.5308\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=100,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          batch_size=10\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history[:25]['loss'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,r2_score,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:0.5307736709713936\n",
      "RMSE:0.6503278048894485\n",
      "R2:0.3528347944472803\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE:{mean_absolute_error(y_test,predictions)}\")\n",
    "print(f\"RMSE:{np.sqrt(mean_squared_error(y_test,predictions))}\")\n",
    "print(f\"R2:{r2_score(y_test,predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_stats=[[7.8,0.88,0,2.6,0.098,25.0,67.0,0.9968,3.2,0.68,9.8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(wine_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.303438]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,b=model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:<tf.Variable 'dense/kernel:0' shape=(11, 1) dtype=float32, numpy=\n",
      "array([[ 0.03616715],\n",
      "       [-0.48064008],\n",
      "       [ 0.19846526],\n",
      "       [ 0.01755887],\n",
      "       [-0.6801303 ],\n",
      "       [ 0.00659177],\n",
      "       [-0.00121173],\n",
      "       [ 0.7583458 ],\n",
      "       [ 0.0230985 ],\n",
      "       [ 0.7714924 ],\n",
      "       [ 0.37737498]], dtype=float32)>\n",
      "Biases:<tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.32896513], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Weights:{w}\\nBiases:{b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=[0.049,-0.932,-0.062,0.014,-0.469,0.004,-0.003,0.560,0.321,0.781,0.315]\n",
    "bias=0.308\n",
    "inputs=[7.8,0.88,0,2.6,0.098,25.0,67.0,0.9968,3.2,0.68,9.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=0\n",
    "for i in range(len(weights)):\n",
    "    ans+=weights[i]*inputs[i]\n",
    "ans+=bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.962966"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
